\section{Introduction}

Differential Privacy (DP) \cite{dwork2006calibrating} is a rigorous notion of data privacy, used to protect against a host of different privacy attacks, including membership inference \cite{homer2008resolving,dwork2015robust,carlini2022membership} and data reconstruction \cite{dinur2003revealing,dwork2007price,carlini2021extracting,balle2022reconstructing,dick2023confidence,nasr2023scalable}.
As such, there is a sustained push to integrate and deploy DP in a large number of applications \cite{opendp-registry}, from machine learning (ML) and artificial intelligence (AI) models \cite{kairouz2021practical,sinha2025vaultgemma}, to analytics collection \cite{rogers2020linkedin,apple-emoji,ding2017collecting}, to data releases \cite{adeleye2023publishing,abowd20222020}, as well as in general libraries and systems supporting those applications \cite{gaboardi2020programming,wilson2020differentially,jax-privacy2022github,tholoniat2024cookie,ghazi2025differential}. % latter is systems and DB work, ad measurement, OpenDP, Google DP, libraries, ...
%
This practical DP push also motivates important theoretical progress.

A prominent direction of theoretical improvement comes from alternative definitions of DP, that enable tighter privacy loss accounting under composition and improve the privacy-accuracy tradeoff. The most successful definitions include $(\epsilon, \delta)$-DP \cite{dwork2006our} (known as approximate DP), the R\'enyi divergence family of DP definitions such as zCDP \cite{dwork2016concentrated,bun2016concentrated} and RDP \cite{mironov2017renyi}, and privacy definitions that generalize approximate DP by considering all $(\epsilon, \delta)$-DP values compatible with a given mechanism, such as the privacy loss distribution (PLD) \cite{sommer2019privacy} and $f$-DP \cite{dong2022gaussian}.
The latter definitions, PLD and $f$-DP, are theoretically appealing as they tightly capture resilience to membership inference attacks framed as hypothesis tests \cite{WassermanZ10,dong2022gaussian}. However, composition under these definitions is more complex and can be computationally difficult, with analyses of specific algorithms that rely on numerical approaches to handle composition in practice \cite{koskela2020computing,gopi2021numerical}.

Two other theoretical improvements enable new forms of composition that are necessary requirements for practical, real world DP usage.
First, concurrent composition \cite{vadhan2021concurrent} supports composition of DP mechanisms running over multiple rounds of interaction with the user---such as the sparse vector technique \cite{dwork2009complexity}---that are running in parallel.
This is required in practical systems which typically have to handle queries from multiple parties simultaneously, and where it is not possible to enforce a sequential ordering of the queries. Even individual users may want to run DP computations concurrently with long-running, multi-step mechanism (e.g., \cite{kostopoulou2023turbo}).

Second, adaptive composition, the main topic of this paper, enables the composition of DP mechanisms with adaptively chosen privacy parameters (as opposed to regular composition, in which these parameters have to be known in advance).
Adaptive composition is formalized through the notion of \emph{privacy filters} \cite{RRUV16}, which accept DP mechanisms as long as their composition remains within a bound fixed in advance  (more details in \S\ref{sec:preliminaries}).
Such adaptive composition is necessary to support long running applications, in which analysts can adaptively query a system with mechanisms and DP parameters of their choice \cite{lecuyer2019privacy,kostopoulou2023turbo,kuchler2024cohere}.
Furthermore, filters enable crucial privacy accounting savings through advanced versions of parallel composition \cite{lecuyer2019privacy}, as well as individual (personalized) DP \cite{ebadi2015differential}, which enables data dependent privacy accounting in ML model training \cite{feldman2021individual,yu2022individual} and measurement systems \cite{tholoniat2024cookie,ghazi2025differential}.

A key question in DP composition is whether these various improvements combine with each other.
%
Ideally these more flexible forms of composition come for free: that is, that can we apply composition results under concurrent mechanisms or adaptive budgets using privacy filters, without a penalty in the final privacy loss after composition.
Flexible composition for free is important not only because it is efficient privacy-wise, but also because it enables reusing all existing composition results, including tight analyses for specific mechanisms and empirical computational results.

As it turns out, concurrent composition is indeed free for all DP definitions \cite{vadhan2023concurrent,lyu2022composition}.
Moreover, concurrent and adaptive filter composition reduces to adaptive filters \cite{haney2023concurrent}, and thus has the same composition cost.
%
Therefore, the full expressivity of both concurrency and adaptivity hinges on free privacy filter composition for different notions of DP.
%
Filters, however, are not as well understood.
We know that adaptive composition under privacy filters is free for $\epsilon$-DP \cite{RRUV16} and R\'enyi-based DP definitions \cite{FZ21,lecuyer2021practical} (zCDP, RDP). Filters are also free for Gaussian mechanisms under $f$-DP and PLD accounting \cite{ST22,KTH22}. However, for $(\epsilon, \delta)$-DP, the best known result for adaptive composition with filters is only asymptotically free, with worse constants than non-adaptive composition \cite{WRRW23}. Even less is known about filters under $f$-DP and PLD. In particular, we consider \emph{natural filters}, which leverage lossless composition of the privacy characteristics of individual queries. Natural filters can be realized via PLDs, privacy profiles, or $f$-DP accounting.
In this paper, we make three important contributions towards fully understanding natural privacy filters:
\begin{itemize}
	\item First, in \S\ref{sec:adversary_theory} we present a general theory of adaptive mechanisms that issue adversarial queries with a constrained per-query privacy cost.
	\item In \S\ref{sec:natural_filter_characterization} we apply this theory to the natural filter and, surprisingly, we show that adaptive composition is NOT free under the PLD nor $f$-DP notions of privacy (see \Cref{corollary:no-free-filters}).
	\item Finally, we show in \S\ref{sec:well_ordering_proof} that filters are only free for very restricted families of mechanisms: those that are closed under composition, and admit totally ordered tradeoff functions.
	% \item Families admitting free filters are XXX (KL characterization) (\S\ref{}).
	% \item We then quantify the cost of adaptivity, showing for the first time an XXX-bound on the privacy cost of adaptive composition for PLD (\S\ref{}).
\end{itemize}

Our work also includes some minor contributions including that PLDs can be assigned a natural ordering satisfying a completeness property enabling one to take a supremum of PLDs (see \Cref{prop:sup-conv}). As far as we are aware this property has not been documented in the privacy accounting literature. We alo document in \S\ref{sec:implications-special-case} some families of queries and budgets that do and do not admit free filters. 
