\section{Introduction}

There is a sustained push to integrate and deploy differential privacy (DP) in a large number of applications \cite{opendp-registry}, from machine learning (ML) and artificial intelligence (AI) models \cite{kairouz2021practical,sinha2025vaultgemma}. This practical push also motivates theoretical development to reduce the cost and increase the flexibility of DP. A prominent theoretical development over the last few years is exact and efficient privacy loss accounting under composition based on the privacy loss distribution (PLD), privacy profile, and $f$-DP formalisms \cite{sommer2019privacy, dong2022gaussian}.

Fully adaptive composition, the main topic of this paper, concerns the composition of DP mechanisms with interactively chosen privacy characteristics. This is needed to support long-running applications in which analysts may interactively re-assess the privacy budget allocated to each query in order to meet operational needs \cite{lecuyer2019privacy,kostopoulou2023turbo,kuchler2024cohere}. Fully adaptive composition is formalized in terms of \emph{privacy filters} \cite{RRUV16}, which accept any series of private queries as long as their composition has privacy characteristics satisfying some budget that is fixed in advance.

A key research direction is to investigate whether improvements in privacy accounting are compatible with fully adaptive composition. We know that privacy filters are free for $\epsilon$-DP \cite{RRUV16} and R\'enyi-based (zCDP, RDP) DP accounting \cite{FZ21,lecuyer2021practical}. Filters are also free for Gaussian mechanisms under $f$-DP and PLD accounting \cite{ST22,KTH22}. However, the best known result for filters based on $(\epsilon, \delta)$-DP accounting only shows that these filters are asymptotically free, with worse constants than non-adaptive composition \cite{WRRW23}. Even less is known about filters leveraging exact accounting (PLD, privacy profile, $f$-DP) techniques for general classes of mechanisms. We refer to filters based on lossless privacy accounting as \emph{natural filters}. In this paper, we make three important contributions towards fully understanding natural privacy filters:
\begin{itemize}
	\item First, in \S\ref{sec:adversary_theory} we present a general theory of adaptive mechanisms that issue adversarial queries with a constrained per-query privacy cost.
	\item In \S\ref{sec:natural_filter_characterization} we apply this theory to the natural filter and, surprisingly, we show that adaptive composition is NOT free under the PLD nor $f$-DP notions of privacy (see \Cref{corollary:no-free-filters}).
	\item Finally, we show in \S\ref{sec:well_ordering_proof} that filters are only free for very restricted families of mechanisms: those that are closed under composition, and admit totally ordered tradeoff functions.
\end{itemize}

Our work also includes some minor contributions including that PLDs can be assigned a natural ordering satisfying a completeness property enabling one to take a supremum of PLDs (see \Cref{prop:pld_sup}). As far as we are aware this property has not been documented in the privacy accounting literature. We alo document in \S\ref{sec:implications-special-case} some families of queries and budgets that do and do not admit free filters. 
