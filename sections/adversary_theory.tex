\section{Query-Restricted Adversaries}
\label{sec:adversary_theory}

In this section we develop a general theory of the privacy characteristics of adversarial adaptive mechanism when the queries the adversary may issue are restricted. This will lead directly to a theory of natural filters as we will see in \S\ref{sec:natural_filter_characterization}. For simplicity, we will assume that an adversary may always ``pass'' its turn by issuing a query with no privacy loss.

\begin{definition}
	Let $k$ be a positive integer. We define a privacy rule of length $k$ as a map $\Gamma$ that takes a sequence of PLDs $(L_1, \dots, L_{k'})$ ($0 \leq k' < k$) and outputs some collection of PLDs including $\Iddist$. We define a $\Gamma$-adversary as an adaptively composed mechanism $M = M_1 \otimes \dots \otimes M_k$ such that
	\begin{align*}
		L_i := \pld(M_i(\cdot; y_1, \dots, y_{i - 1})) \in \Gamma(L_1, \dots, L_{i - 1})
	\end{align*}
	for every $(y_1, \dots, y_{k - 1}) \in \cY_1 \times \dots \times \cY_{k - 1}$.
	% \matt{can relax to with probability 1 over (Y_i)_i}
	We will write $\Adv(\Gamma)$ to denote the set of $\Gamma$-adversaries and we will denote by
	\begin{align*}
		\pld(\Gamma) := \sup\{\pld(M) : M \in \Adv(\Gamma)\}
	\end{align*}
	the worst-case privacy loss of arbitrary $\Gamma$-adversaries.
\end{definition}

Crucially, notice that that no single adversary fully realizes the privacy cost of the rule $\Gamma$. Recalling the $f$-DP interpretation of the supremum (see \Cref{prop:sup-conv}), the privacy cost of the rule $\Gamma$ is in fact realized by a family of adversaries that minimize the false negative rate for every given confidence level. It turns out that the maximum privacy cost of the rule $\Gamma$ for a given confidence level occurs when the adversary first plays the best move for this confidence level, observes the outcome, then depending on the likelihood of having observed this outcome recursively chooses its remaining strategy tuned to maximize the overall privacy cost. Note that by $\lambda$ we mean the empty sequence.

\begin{lemma}
	\label{lemma:restricted_adversary}
	Let $\Gamma$ be a rule of length $k$. If $k = 1$, then $\pld(\Gamma) = \sup{\Gamma(\lambda)}$ and, for $k > 1$, we have
	\begin{align*}
		\pld(\Gamma) = \sup\{L \oplus \pld(\Gamma_L) : L \in \Gamma(\lambda)\}
	\end{align*}
	where $\Gamma_{L_0}(L_1, \dots, L_{k'}) := \Gamma(L_0, L_1, \dots L_{k'})$ denotes the rule of length of $k - 1$ that fixes the first move played against $\Gamma$ to $L_0$.
\end{lemma}

We prove the result by passing to hockey-stick curves because a pointwise supremum is easier to work with rather than the lower convex envelope. We will essentially show that a worst-case adversary first plays an optimal move with corresponding PLD $L$, observes the outcome $Y_1$, and adversarially chooses a followup in $\Adv(\Gamma_L)$ to ensure that the overall process ``traces out'' the hockey-stick curve of $L \oplus \Adv(\Gamma_L)$.

\begin{proof}
	The case where $k = 1$ is immediate, so we assume $k > 1$. We first show that
	\begin{align*}
		\pld(\Gamma) \preceq \sup\{L \oplus \pld(\Gamma_L) : L \in \Gamma(\lambda)\}.
	\end{align*}
	To that end, consider any $\Gamma$-adversary $M$. Decompose $M$ as the adaptive composition of $M_1(\cdot)$ with some $M'(\cdot; y_1)$ and let $L := \pld(M_1) \in \Gamma(\lambda)$. Then, clearly, for every fixed $y_1$, $M'(\cdot; y_1)$ is a $\Gamma_L$-adversary and, in particular, $\pld(M'(\cdot; y_1)) \preceq \pld(\Gamma_L)$. By \Cref{prop:composition_convolution}, we have that $\pld(M) \preceq L \otimes \pld(\Gamma_L)$ and the desired inequality follows by taking suprema.

	More surprising is the reverse inequality, which we prove constructively by passing to hockey-stick curves. Let $L \in \Gamma(\lambda)$, let $x \in \bR^\times$, and let $\gamma > 0$. Choose any mechanism $M_1$ that has PLD $L$ and let $\ell_1 := \frac{dM_1(D_1)}{dM_1(D_2)}$ denote the corresponding likelihood function. Moreover, for any $x \in \R^\times$ we can choose by \Cref{prop:sup-conv}, a $\Gamma_L$-adversary $M^x$ such that
	\begin{align*}
		H_x(M^x) \geq \sup_{M' \in \Adv(\Gamma_L)}H_x(M') - \gamma.
	\end{align*}
	Now consider the $\Gamma$-adversary $M := M_1 \otimes M_2$ where $M_2(D; y_1) := M^{x/\ell_1(y_1)}(D)$. By \Cref{prop:hockey_stick_composition}, we get
	\begin{align*}
		h_M(x)
			& = \E_{Y_1 \sim M_1(D_1)}[h_{M_{x/\ell_1(Y_1)}}(x/\ell_1(Y_1))] \\
			& \geq \E_{Y_1 \sim M_1(D_1)}[\sup_{M' \in \Adv(\Gamma_L)}h_{M'}(x/\ell_1(Y_1)) - \gamma] \\
			& = (h_{M_1} \otimes \sup_{M' \in \Adv(\Gamma_L)} h_{M'})(x) - \gamma.
	\end{align*}
	Again, taking suprema, we get that
	\begin{align*}
		\sup_{M \in \Adv(\Gamma)} h_M \succeq h_{M_1} \otimes \sup_{M' \in \Adv(\Gamma_L)} h_{M'},
	\end{align*}
	and thus $\pld(\Gamma) \succeq L \otimes \pld(\Gamma_L)$, which completes the proof since $L$ was arbitrary.
\end{proof}
