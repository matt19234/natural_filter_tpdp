\section{Query-Restricted Adversaries}
\label{sec:adversary_theory}

In this section we develop a general theory of the privacy characteristics of adversarial adaptive mechanism when the queries the adversary may issue are restricted. This will lead directly to a theory of natural filters as we will see in \S\ref{sec:natural_filter_characterization}. For simplicity, we will assume that an adversary may always ``pass'' its turn by issuing a query with no privacy loss.

\begin{definition}
	Let $k$ be a positive integer. We define a privacy rule of length $k$ as a map $\Gamma$ that takes a sequence of PLDs $(L_1, \dots, L_{k'})$ ($0 \leq k' < k$) and outputs some collection of PLDs including $\Iddist$. We define a $\Gamma$-adversary as an adaptively composed mechanism $M = M_1 \otimes \dots \otimes M_k$ such that
	\begin{align*}
		L_i := \pld(M_i(\cdot; y_1, \dots, y_{i - 1})) \in \Gamma(L_1, \dots, L_{i - 1})
	\end{align*}
	for every $(y_1, \dots, y_{k - 1}) \in \cY_1 \times \dots \times \cY_{k - 1}$.
	% \matt{can relax to with probability 1 over (Y_i)_i}
	We will write $\Adv(\Gamma)$ to denote the set of $\Gamma$-adversaries and we will denote by
	\begin{align*}
		\pld(\Gamma) := \sup\{\pld(M) : M \in \Adv(\Gamma)\}
	\end{align*}
	the worst-case privacy loss of arbitrary $\Gamma$-adversaries.
\end{definition}

Crucially, notice that that no single adversary fully realizes the privacy cost of the rule $\Gamma$. The privacy cost of the rule $\Gamma$ is in fact realized by a family of adversaries that minimize the false negative rate for every given confidence level. It turns out that the maximum privacy cost of the rule $\Gamma$ for a given confidence level occurs when the adversary first plays the best move for this confidence level, observes the outcome, then depending on the likelihood of having observed this outcome recursively chooses its remaining strategy tuned to maximize the overall privacy cost. Note that by $\lambda$ we mean the empty sequence.

\begin{lemma}
	\label{lemma:restricted_adversary}
	Let $\Gamma$ be a rule of length $k$. If $k = 1$, then $\pld(\Gamma) = \sup{\Gamma(\lambda)}$ and, for $k > 1$, we have
	\begin{align*}
		\pld(\Gamma) = \sup\{L \oplus \pld(\Gamma_L) : L \in \Gamma(\lambda)\}
	\end{align*}
	where $\Gamma_{L_0}(L_1, \dots, L_{k'}) := \Gamma(L_0, L_1, \dots L_{k'})$ denotes the rule of length of $k - 1$ that fixes the first move to $L_0$.
\end{lemma}

% We prove the result by passing to hockey-stick curves because a pointwise supremum is easier to work with rather than the lower convex envelope. We will essentially show that a worst-case adversary first plays an optimal move with corresponding PLD $L$, observes the outcome $Y_1$, and adversarially chooses a followup in $\Adv(\Gamma_L)$ to ensure that the overall process ``traces out'' the hockey-stick curve of $L \oplus \Adv(\Gamma_L)$. See \Cref{app:restricted_adversary_proof} for the details.
